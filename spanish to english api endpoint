import os
import traceback

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from transformers import T5ForConditionalGeneration, T5Tokenizer

# ——————————————————————————————————————————————————————————————
# 1. Device & model path
# ——————————————————————————————————————————————————————————————
os.environ["CUDA_VISIBLE_DEVICES"] = "3"
LORA_ADAPTER_PATH = os.getenv(
    "LORA_PATH",
    "/app/cortex/dev1/aptaiModels/madlad_merged_LORA_8_v6"
)

# ——————————————————————————————————————————————————————————————
# 2. Load tokenizer + model
# ——————————————————————————————————————————————————————————————
tokenizer = T5Tokenizer.from_pretrained(LORA_ADAPTER_PATH)
model     = T5ForConditionalGeneration.from_pretrained(LORA_ADAPTER_PATH)
model.eval()

# Make sure the tokenizer knows about the special token `<2en>`
# (Usually T5 has language‐tags built in; if yours doesn’t you can add it)
if "<2en>" not in tokenizer.get_vocab():
    tokenizer.add_special_tokens({"additional_special_tokens": ["<2en>"]})
    model.resize_token_embeddings(len(tokenizer))

# Grab the integer ID for `<2en>` once
prefix_id = tokenizer.convert_tokens_to_ids("<2en>")

# ——————————————————————————————————————————————————————————————
# 3. FastAPI setup
# ——————————————————————————————————————————————————————————————
app = FastAPI(
    title="Spanish→English Translation",
    description="Only translates Spanish to English (enforced).",
    version="1.0.0",
)

class TranslateRequest(BaseModel):
    input: str
    source: str   # must be "es"
    target: str   # must be "en"

class TranslateResponse(BaseModel):
    output: str

@app.get("/")
async def health_check():
    ok = tokenizer is not None and model is not None
    return {
        "status": "healthy" if ok else "failed",
        "lora_adapter": LORA_ADAPTER_PATH
    }

@app.post("/translate/", response_model=TranslateResponse)
async def translate(req: TranslateRequest):
    text = req.input.strip()
    if not text:
        raise HTTPException(400, "Input text must be non-empty")

    # enforce Spanish → English only
    if req.source.lower() != "es" or req.target.lower() != "en":
        raise HTTPException(
            400,
            "Only Spanish-to-English supported: source='es', target='en'"
        )

    # (optional) quick language check
    # from langdetect import detect
    # if detect(text) != "es":
    #     raise HTTPException(400, "Input text should be Spanish")

    # tokenize the raw Spanish text **without** adding any extra T5 prefix tokens
    enc = tokenizer(text, return_tensors="pt", add_special_tokens=False).input_ids.to(model.device)

    try:
        # generate, **forcing** the decoder to start with <2en>
        out = model.generate(
            enc,
            decoder_start_token_id=prefix_id,
            max_length=512,
            num_beams=4,
            early_stopping=True,
        )
        # decode skipping ALL special tokens
        translated = tokenizer.decode(out[0], skip_special_tokens=True)
        return TranslateResponse(output=translated)

    except Exception as e:
        tb = traceback.format_exc()
        # (optionally log tb somewhere)
        raise HTTPException(500, f"Translation failed: {e}")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("translation_app:app", host="0.0.0.0", port=8100, reload=True)